{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header = None)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values\n",
    "Y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.1,  3.5,  1.4,  0.2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le_Y = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = le_Y.fit_transform(Y)\n",
    "Y = Y.reshape(len(Y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_Y = OneHotEncoder(categorical_features = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = ohe_Y.fit_transform(Y).toarray()\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.90068117,  1.03205722, -1.3412724 , -1.31297673])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sc_X.fit_transform(X)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = X.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = Y.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Y = W1.X1 + ... + W4.X4 + B\n",
    "output = softmax(Y)\n",
    "Create Weights (W) and Biases (B) Variables\n",
    "'''\n",
    "\n",
    "W = tf.Variable(tf.zeros([num_features, num_classes]))\n",
    "B = tf.Variable(tf.zeros([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create x and y_ placeholders for holding actual data\n",
    "x = tf.placeholder(tf.float32, [None, num_features])\n",
    "y_ = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate y which holds the model's predicted logit values\n",
    "Wx = tf.matmul(x, W)\n",
    "y = Wx + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create cost function to minimize\n",
    "cost_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create optimizer to minimize the cost function\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5).minimize(cost_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainTheData(num_steps, optimizer_to_use, batch_size):\n",
    "    init = tf.global_variables_initializer()\n",
    "    # initialize all global variables\n",
    "    \n",
    "    # create a session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for i in range(num_steps):\n",
    "            \n",
    "            # Calculate batch start index\n",
    "            if batch_size == len(X_train):\n",
    "                batch_start_index = 0\n",
    "            elif batch_size > len(X_train):\n",
    "                raise ValueError(\"Batch Size : \" + str(batch_size) + \" cannot be greater than Data Size : \", len(X_train))\n",
    "            else:\n",
    "                batch_start_index = (i * batch_size) % (len(X_train) - batch_size)\n",
    "                \n",
    "            # Calculate batch end index\n",
    "            batch_end_index = batch_size + batch_start_index\n",
    "            \n",
    "            # Create Batch X and Y Values\n",
    "            batch_X_values = X_train[batch_start_index : batch_end_index]\n",
    "            batch_Y_values = Y_train[batch_start_index : batch_end_index]\n",
    "            \n",
    "            # Create feed dict to feed it to the optimizer\n",
    "            feed = {x : np.array(batch_X_values), y_ : np.array(batch_Y_values)}\n",
    "            \n",
    "            sess.run(optimizer_to_use, feed_dict = feed)\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(\"After \" + str(i + 1) + \" iterations, cost : \", sess.run(cost_cross_entropy, feed_dict = feed))\n",
    "                print(\"W : \", sess.run(W))\n",
    "                print(\"B : \", sess.run(B))\n",
    "                print(\"\")\n",
    "        \n",
    "        # Store model's predicted logit values\n",
    "        Y_pred_logits = sess.run(y, feed_dict = {x : np.array(X_test)})\n",
    "        \n",
    "        # Convert it to tensors\n",
    "        Y_pred_logits_tensor = tf.convert_to_tensor(np.array(Y_pred_logits))\n",
    "        \n",
    "        # Apply softmax function\n",
    "        apply_softmax = tf.nn.softmax(Y_pred_logits_tensor)\n",
    "        \n",
    "        # Store model's predicted classes\n",
    "        Y_pred_classes = np.argmax(sess.run(apply_softmax), axis = 1)\n",
    "            \n",
    "        sess.close()\n",
    "    return Y_pred_classes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 50 iterations, cost :  0.236154\n",
      "W :  [[-0.77554309  0.33894774  0.43659544]\n",
      " [ 0.94955462 -0.65572196 -0.29383257]\n",
      " [-1.21106172  0.0500053   1.1610564 ]\n",
      " [-1.13366997 -0.44651961  1.58018994]]\n",
      "B :  [-0.4792183   1.10209072 -0.62287265]\n",
      "\n",
      "After 100 iterations, cost :  0.166916\n",
      "W :  [[-0.98325914  0.54376578  0.4394936 ]\n",
      " [ 1.21277785 -0.58903182 -0.62374628]\n",
      " [-1.57853818 -0.05927002  1.63780797]\n",
      " [-1.47997522 -0.72124046  2.20121503]]\n",
      "B :  [-0.55887634  1.63064826 -1.07177222]\n",
      "\n",
      "After 150 iterations, cost :  0.133598\n",
      "W :  [[-1.12603462  0.66531616  0.46071887]\n",
      " [ 1.39155555 -0.5486865  -0.8428697 ]\n",
      " [-1.83635867 -0.15704125  1.99339998]\n",
      " [-1.72565067 -0.89455086  2.62020087]]\n",
      "B :  [-0.58191395  1.99051607 -1.40860248]\n",
      "\n",
      "After 200 iterations, cost :  0.113832\n",
      "W :  [[-1.23471391  0.75358433  0.48112971]\n",
      " [ 1.52773297 -0.52445674 -1.00327682]\n",
      " [-2.03578758 -0.24512003  2.28090835]\n",
      " [-1.91680086 -1.0186553   2.93545604]]\n",
      "B :  [-0.5871973   2.26398158 -1.67678428]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_classes = trainTheData(num_steps = 200, optimizer_to_use = optimizer, batch_size = len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_classes = np.argmax(Y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_classes, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0,  4,  1],\n",
       "       [ 0,  1,  8]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test_classes, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
