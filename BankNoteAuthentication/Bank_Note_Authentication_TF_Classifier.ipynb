{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data_banknote_authentication.txt', header = None)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values\n",
    "Y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ..., \n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ..., \n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.reshape(len(Y), 1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_Y = OneHotEncoder(categorical_features = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = ohe_Y.fit_transform(Y).toarray()\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = X.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = Y.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y = W1.X1 + W2.X2 + ... + Wn.Xn + B\n",
    "# output = 1 / (1 + e ^ (- Y))\n",
    "# Create Weights and Biases Variables\n",
    "\n",
    "W = tf.Variable(tf.zeros([num_features, num_classes]))\n",
    "B = tf.Variable(tf.zeros([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create x and y_ placeholders to hold actual data\n",
    "x = tf.placeholder(tf.float32, [None, num_features])\n",
    "y_ = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate y which holds the model's predicted values\n",
    "Wx = tf.matmul(x, W)\n",
    "y = Wx + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a cost function to minimize\n",
    "cost_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an Optimizer to minimize the cost\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5).minimize(cost_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainTheData(num_steps, optimizer_to_use, batch_size):\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Initialize all the global variables\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for i in range(num_steps):\n",
    "            \n",
    "            # Calculate the batch start index\n",
    "            if batch_size == len(X_train):\n",
    "                batch_start_index = 0\n",
    "            elif batch_size > len(X_train):\n",
    "                raise ValueError(\"Batch Size : \" + str(batch_size) + \" cannot be greater than Data Size : \", len(X_train))\n",
    "            else:\n",
    "                batch_start_index = (i * batch_size) % (len(X_train) - batch_size)\n",
    "            \n",
    "            # Calculate the batch end index\n",
    "            batch_end_index = batch_size + batch_start_index\n",
    "            \n",
    "            # Create batch X and Y values\n",
    "            batch_X_values = X_train[batch_start_index : batch_end_index]\n",
    "            batch_Y_values = Y_train[batch_start_index : batch_end_index]\n",
    "            \n",
    "            # Create feed dict to feed the optimizer\n",
    "            feed = {x : np.array(batch_X_values), y_ : np.array(batch_Y_values)}\n",
    "            \n",
    "            sess.run(optimizer_to_use, feed_dict = feed)\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(\"After \" + str(i + 1) + \" iterations, cross_entropy : \", sess.run(cost_cross_entropy, feed_dict = feed))\n",
    "                print(\"W : \", sess.run(W))\n",
    "                print(\"B : \", sess.run(B))\n",
    "        \n",
    "        # Calculate the predicted values for Test Data\n",
    "        Y_pred = sess.run(y, feed_dict = {x : np.array(X_test)})\n",
    "        \n",
    "        # Convert the logits into tensors\n",
    "        Y_pred_tensors = tf.convert_to_tensor(np.array(Y_pred))\n",
    "        \n",
    "        # Apply softmax function to the tensors of logits\n",
    "        apply_softmax = tf.nn.softmax(Y_pred_tensors)\n",
    "        \n",
    "        # Calculate the class to which it belongs\n",
    "        Y_pred = np.argmax(sess.run(apply_softmax), axis = 1)\n",
    "        \n",
    "        sess.close()\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 50 iterations, cross_entropy :  0.0497393\n",
      "W :  [[ 0.93982112 -0.93982112]\n",
      " [ 0.54547602 -0.54547596]\n",
      " [ 0.62691528 -0.62691534]\n",
      " [ 0.15182392 -0.15182397]]\n",
      "B :  [-0.82157236  0.82157254]\n",
      "After 100 iterations, cross_entropy :  0.038668\n",
      "W :  [[ 1.08588433 -1.08588421]\n",
      " [ 0.6247645  -0.62476426]\n",
      " [ 0.74108493 -0.74108523]\n",
      " [ 0.10866363 -0.10866367]]\n",
      "B :  [-1.12573004  1.1257304 ]\n",
      "After 150 iterations, cross_entropy :  0.0343103\n",
      "W :  [[ 1.20006168 -1.20006156]\n",
      " [ 0.68346691 -0.68346661]\n",
      " [ 0.82289255 -0.82289284]\n",
      " [ 0.08949518 -0.08949527]]\n",
      "B :  [-1.30042565  1.30042601]\n",
      "After 200 iterations, cross_entropy :  0.031887\n",
      "W :  [[ 1.2945708  -1.29457068]\n",
      " [ 0.73191404 -0.73191363]\n",
      " [ 0.88879639 -0.88879681]\n",
      " [ 0.08097432 -0.08097441]]\n",
      "B :  [-1.4208802   1.42088044]\n",
      "After 250 iterations, cross_entropy :  0.0302975\n",
      "W :  [[ 1.37574267 -1.37574255]\n",
      " [ 0.77357823 -0.77357781]\n",
      " [ 0.94466412 -0.94466454]\n",
      " [ 0.07768676 -0.07768682]]\n",
      "B :  [-1.51247013  1.51247036]\n",
      "After 300 iterations, cross_entropy :  0.0291519\n",
      "W :  [[ 1.44716918 -1.44716907]\n",
      " [ 0.81028652 -0.81028599]\n",
      " [ 0.99345094 -0.99345148]\n",
      " [ 0.07720839 -0.07720847]]\n",
      "B :  [-1.58652377  1.58652389]\n",
      "After 350 iterations, cross_entropy :  0.0282753\n",
      "W :  [[ 1.51110601 -1.5111059 ]\n",
      " [ 0.84317809 -0.8431775 ]\n",
      " [ 1.03691268 -1.03691304]\n",
      " [ 0.07832386 -0.07832392]]\n",
      "B :  [-1.64894974  1.64894986]\n",
      "After 400 iterations, cross_entropy :  0.0275763\n",
      "W :  [[ 1.56907868 -1.56907868]\n",
      " [ 0.87302691 -0.87302637]\n",
      " [ 1.07619679 -1.07619715]\n",
      " [ 0.08037147 -0.0803715 ]]\n",
      "B :  [-1.70316148  1.70316148]\n",
      "After 450 iterations, cross_entropy :  0.0270021\n",
      "W :  [[ 1.62217486 -1.62217498]\n",
      " [ 0.90038651 -0.90038598]\n",
      " [ 1.11210203 -1.11210251]\n",
      " [ 0.08296909 -0.08296911]]\n",
      "B :  [-1.75128043  1.75128031]\n",
      "After 500 iterations, cross_entropy :  0.0265195\n",
      "W :  [[ 1.67120183 -1.67120206]\n",
      " [ 0.92566866 -0.92566818]\n",
      " [ 1.1452105  -1.14521086]\n",
      " [ 0.08588676 -0.08588672]]\n",
      "B :  [-1.79470229  1.79470217]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_classes = trainTheData(num_steps = 500, optimizer_to_use = optimizer, batch_size = len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_classes = np.argmax(Y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99708454810495628"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_classes, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[195,   1],\n",
       "       [  0, 147]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test_classes, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
