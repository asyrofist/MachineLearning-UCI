{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"diagnosis.data\", header = None, delimiter = r\"\\s+\")\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.5</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.9</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1    2    3    4    5    6   7\n",
       "0  35.5  no  yes   no   no   no   no  no\n",
       "1  35.9  no   no  yes  yes  yes  yes  no\n",
       "2  35.9  no  yes   no   no   no   no  no\n",
       "3  36.0  no   no  yes  yes  yes  yes  no\n",
       "4  36.0  no  yes   no   no   no   no  no"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:6].values\n",
    "Y1 = dataset.iloc[:, 6:7].values\n",
    "Y2 = dataset.iloc[:, 7:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le_Y = LabelEncoder()\n",
    "Y1 = le_Y.fit_transform(Y1)\n",
    "Y2 = le_Y.transform(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y1 = Y1.reshape(len(Y1), 1)\n",
    "Y2 = Y2.reshape(len(Y2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_Y = OneHotEncoder(categorical_features = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = ohe_Y.fit_transform(Y1).toarray()\n",
    "Y1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2 = ohe_Y.transform(Y2).toarray()\n",
    "Y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder_X(index):\n",
    "    le_X = LabelEncoder()\n",
    "    X[:, index] = le_X.fit_transform(X[:, index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    encoder_X(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.77979629, -0.56451866,  0.84515425, -1.41421356, -0.98346994,\n",
       "       -0.84515425])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X, Y1, test_size = 0.2, random_state = 4)\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y2, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = X.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = Y1.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y = W1.X1 + W2.X2 + ... + Wn.Xn + B\n",
    "# output = 1 / (1 + e ^ (- Y))\n",
    "# Create Weights and Biases Variables\n",
    "\n",
    "W = tf.Variable(tf.zeros([num_features, num_classes]))\n",
    "B = tf.Variable(tf.zeros([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create x and y_ placeholders to hold actual data\n",
    "x = tf.placeholder(tf.float32, [None, num_features])\n",
    "y_ = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate y which holds the model's predicted values\n",
    "Wx = tf.matmul(x, W)\n",
    "y = Wx + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a cost function to minimize\n",
    "cost_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an Optimizer to minimize the cost\n",
    "# Use different Optimizers to compare which suits the given problem\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5).minimize(cost_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainTheData(num_steps, optimizer_to_use, batch_size, X_train, Y_train, X_test):\n",
    "    init = tf.global_variables_initializer()\n",
    "    # initialize the global variables\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for i in range(num_steps):\n",
    "            \n",
    "            # Calculate the batch start index\n",
    "            if batch_size == len(X_train):\n",
    "                batch_start_index = 0\n",
    "            elif batch_size > len(X_train):\n",
    "                raise ValueError(\"Batch Size : \" + str(batch_size) + \" cannot be greater than Data Size : \", len(X_train))\n",
    "            else:\n",
    "                batch_start_index = (i * batch_size) % (len(X_train) - batch_size)\n",
    "                \n",
    "            # Calculate the batch end index\n",
    "            batch_end_index = batch_size + batch_start_index\n",
    "            \n",
    "            # Calculate the batch X and Y Values\n",
    "            batch_X_values = X_train[batch_start_index : batch_end_index]\n",
    "            batch_Y_values = Y_train[batch_start_index : batch_end_index]\n",
    "            \n",
    "            # Create feed dict to feed it to the optimizer\n",
    "            feed = {x : np.array(batch_X_values), y_ : np.array(batch_Y_values)}\n",
    "            \n",
    "            sess.run(optimizer_to_use, feed_dict = feed)\n",
    "            \n",
    "            # Print the metrics and other parameters for every 25th iteration\n",
    "            if (i + 1) % 25 == 0:\n",
    "                print(\"After \" + str(i + 1) + \" iterations, cost : \", sess.run(cost_cross_entropy, feed_dict = feed))\n",
    "                print(\"W : \", sess.run(W))\n",
    "                print(\"B : \", sess.run(B))\n",
    "                print(\"\")\n",
    "        \n",
    "        # Calculate the model's predicted logit values\n",
    "        Y_pred_logits = sess.run(y, feed_dict = {x : np.array(X_test)})\n",
    "        \n",
    "        # Convert the logit values to a tensor\n",
    "        Y_pred_logits_tensor = tf.convert_to_tensor(Y_pred_logits)\n",
    "        \n",
    "        # Apply softmax function\n",
    "        apply_softmax = tf.nn.softmax(Y_pred_logits_tensor)\n",
    "        \n",
    "        # Calculate the model's predicted classes\n",
    "        Y_pred_classes = np.argmax(sess.run(apply_softmax), axis = 1)\n",
    "        \n",
    "        sess.close()\n",
    "    return Y_pred_classes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 25 iterations, cost :  0.0635387\n",
      "W :  [[ 0.36048052 -0.36048049]\n",
      " [-0.35461965  0.35461956]\n",
      " [ 0.74408579 -0.74408567]\n",
      " [-1.0390079   1.03900814]\n",
      " [-0.71595895  0.71595913]\n",
      " [ 0.17889084 -0.17889084]]\n",
      "B :  [ 0.00907903 -0.00907903]\n",
      "\n",
      "After 50 iterations, cost :  0.0358602\n",
      "W :  [[ 0.42804849 -0.42804846]\n",
      " [-0.47170502  0.47170499]\n",
      " [ 0.94159371 -0.94159365]\n",
      " [-1.33542526  1.33542538]\n",
      " [-0.85805929  0.85805947]\n",
      " [ 0.24417518 -0.2441752 ]]\n",
      "B :  [ 0.0272304  -0.02723039]\n",
      "\n",
      "After 75 iterations, cost :  0.0252447\n",
      "W :  [[ 0.46254206 -0.46254203]\n",
      " [-0.54670739  0.54670739]\n",
      " [ 1.06801081 -1.06801069]\n",
      " [-1.52046967  1.5204699 ]\n",
      " [-0.94497192  0.9449721 ]\n",
      " [ 0.27927175 -0.27927178]]\n",
      "B :  [ 0.04395306 -0.04395306]\n",
      "\n",
      "After 100 iterations, cost :  0.0195487\n",
      "W :  [[ 0.48453444 -0.48453441]\n",
      " [-0.60238218  0.60238218]\n",
      " [ 1.16253662 -1.1625365 ]\n",
      " [-1.65579653  1.65579689]\n",
      " [-1.00820744  1.00820768]\n",
      " [ 0.30259895 -0.30259901]]\n",
      "B :  [ 0.05837702 -0.05837702]\n",
      "\n",
      "After 125 iterations, cost :  0.0159759\n",
      "W :  [[ 0.50018364 -0.50018364]\n",
      " [-0.64678359  0.64678347]\n",
      " [ 1.23850548 -1.23850536]\n",
      " [-1.76266479  1.76266515]\n",
      " [-1.0580343   1.05803454]\n",
      " [ 0.31981045 -0.31981054]]\n",
      "B :  [ 0.07085378 -0.07085378]\n",
      "\n",
      "After 150 iterations, cost :  0.013519\n",
      "W :  [[ 0.51208466 -0.51208472]\n",
      " [-0.68375915  0.68375909]\n",
      " [ 1.30221081 -1.30221069]\n",
      " [-1.85103011  1.85103047]\n",
      " [-1.09917951  1.09917974]\n",
      " [ 0.33332658 -0.33332673]]\n",
      "B :  [ 0.08177854 -0.08177855]\n",
      "\n",
      "After 175 iterations, cost :  0.0117233\n",
      "W :  [[ 0.52155024 -0.5215503 ]\n",
      " [-0.71546018  0.71546012]\n",
      " [ 1.35716271 -1.35716271]\n",
      " [-1.92637956  1.92637992]\n",
      " [-1.13422942  1.13422954]\n",
      " [ 0.34438962 -0.34438977]]\n",
      "B :  [ 0.09146481 -0.09146481]\n",
      "\n",
      "After 200 iterations, cost :  0.0103521\n",
      "W :  [[ 0.52932602 -0.52932608]\n",
      " [-0.74321616  0.7432161 ]\n",
      " [ 1.40553355 -1.40553355]\n",
      " [-1.99206614  1.99206638]\n",
      " [-1.16476011  1.16476023]\n",
      " [ 0.35371569 -0.35371581]]\n",
      "B :  [ 0.10014915 -0.10014915]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y1_pred_classes = trainTheData(num_steps = 200, optimizer_to_use = optimizer, batch_size = len(X1_train), X_train = X1_train, Y_train = Y1_train, X_test = X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y1_test_classes = np.argmax(Y1_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 25 iterations, cost :  0.0406125\n",
      "W :  [[-0.75100392  0.75100386]\n",
      " [-0.63314885  0.63314891]\n",
      " [-0.89944923  0.89944935]\n",
      " [-0.38147601  0.38147599]\n",
      " [ 0.0063748  -0.00637479]\n",
      " [-0.48020461  0.48020458]]\n",
      "B :  [ 0.17663513 -0.17663509]\n",
      "\n",
      "After 50 iterations, cost :  0.0225144\n",
      "W :  [[-0.90464759  0.90464747]\n",
      " [-0.76825464  0.76825464]\n",
      " [-1.10405803  1.10405815]\n",
      " [-0.49179092  0.49179086]\n",
      " [ 0.03844102 -0.03844102]\n",
      " [-0.59587872  0.59587878]]\n",
      "B :  [ 0.20157337 -0.20157333]\n",
      "\n",
      "After 75 iterations, cost :  0.0158045\n",
      "W :  [[-0.99843419  0.99843413]\n",
      " [-0.85430014  0.85430014]\n",
      " [-1.22835743  1.22835755]\n",
      " [-0.55999815  0.5599981 ]\n",
      " [ 0.05868994 -0.05868995]\n",
      " [-0.66576862  0.66576868]]\n",
      "B :  [ 0.21472223 -0.21472217]\n",
      "\n",
      "After 100 iterations, cost :  0.0122537\n",
      "W :  [[-1.0666008   1.06660092]\n",
      " [-0.91837496  0.91837496]\n",
      " [-1.31826305  1.31826305]\n",
      " [-0.6099273   0.6099273 ]\n",
      " [ 0.07363681 -0.07363681]\n",
      " [-0.7162773   0.71627742]]\n",
      "B :  [ 0.22351944 -0.22351936]\n",
      "\n",
      "After 125 iterations, cost :  0.0100409\n",
      "W :  [[-1.12034047  1.12034059]\n",
      " [-0.96972924  0.96972924]\n",
      " [-1.3888787   1.3888787 ]\n",
      " [-0.64950156  0.6495015 ]\n",
      " [ 0.08556027 -0.08556027]\n",
      " [-0.75595707  0.75595713]]\n",
      "B :  [ 0.23008621 -0.23008615]\n",
      "\n",
      "After 150 iterations, cost :  0.00852379\n",
      "W :  [[-1.16477668  1.1647768 ]\n",
      " [-1.01271915  1.01271915]\n",
      " [-1.44710541  1.44710553]\n",
      " [-0.68237007  0.68237001]\n",
      " [ 0.09552095 -0.09552098]\n",
      " [-0.78869057  0.78869069]]\n",
      "B :  [ 0.23530887 -0.2353088 ]\n",
      "\n",
      "After 175 iterations, cost :  0.00741603\n",
      "W :  [[-1.20269692  1.20269692]\n",
      " [-1.04976463  1.04976463]\n",
      " [-1.49668765  1.49668789]\n",
      " [-0.71052569  0.71052563]\n",
      " [ 0.10409959 -0.10409959]\n",
      " [-0.81657803  0.81657821]]\n",
      "B :  [ 0.23963772 -0.23963763]\n",
      "\n",
      "After 200 iterations, cost :  0.00657015\n",
      "W :  [[-1.23579156  1.23579156]\n",
      " [-1.0823555   1.08235562]\n",
      " [-1.53988695  1.53988719]\n",
      " [-0.73518074  0.73518068]\n",
      " [ 0.11164936 -0.11164936]\n",
      " [-0.84088689  0.84088701]]\n",
      "B :  [ 0.24333145 -0.24333139]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y2_pred_classes = trainTheData(num_steps = 200, optimizer_to_use = optimizer, batch_size = len(X2_train), X_train = X2_train, Y_train = Y2_train, X_test = X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y2_test_classes = np.argmax(Y2_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y1_test_classes, Y1_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0],\n",
       "       [ 0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y1_test_classes, Y1_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y2_test_classes, Y2_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0],\n",
       "       [ 0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y2_test_classes, Y2_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
